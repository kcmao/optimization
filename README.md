# optimization
一些关于算法优化，并行计算的记录

## 评价计算指标和性能指标

评价芯片性能用flops, 衡量程序/模型运算量也用这个flops，所以有点晕了，看了好些资料才有些明白  

一个知乎问题问了这个问题,   
[CNN 模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？](https://www.zhihu.com/question/65305385)   
其中一个答案： 
[chen liu](https://www.zhihu.com/question/65305385/answer/451060549)
首先避免不了这个词：flops   

FLOPS：注意全大写，是floating point operations per second的缩写，意指每秒浮点运算次数，理解为计算速度。是一个衡量硬件性能的指标。   

FLOPs：注意s小写，是floating point operations的缩写（s表复数），意指浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度。   



作者也是如上解释FLOPS概念，是一个衡量硬件性能的指标

在[gemm 从零入门](https://zhuanlan.zhihu.com/p/65436463)这篇知乎中，作者说   
gflops是优化效果的指标。矩阵乘的计算量是2 * M * N * K，拿计算量除以耗时即为当前gemm版本的gflops。如何评估当前还有多大优化空间呢？如果我们能测出芯片的极限gflops，拿芯片的极限和代码的效果做比较，二者接近就说明没有什么提升空间了。如何测试芯片的极限，后续会提供样例

在《并行算法设计与性能优化》这本书中，P48页作者解释了FLOPS: 两个N * N的矩阵相乘，耗时为t.她的FLOPS为2xN3/t,  
作者同时提到一点，用flops衡量程序性能并不适合，因为程序如果降低了算法复杂度的话，其flops反而会降低。按道理是指标越高越好，所以FLOPS比较适用于场合是无法通过算法优化降低运算复杂度，反而可以通过访存等其他优化手段降低运算时间的程序。比如一些运算数量固定不变的程序，比如矩阵乘法等科学计算。因为芯片硬件的浮点运算次数是固定的，当你程序测出来的flops越接近芯片的理论flops,则说明你的程序对硬件的利用率越高。

**注：为什么要计算程序的flops并和芯片理论flops比，这是因为任何程序都很难将cpu的性能完全发挥出来，因为有大量的访存时间导致cpu在等待，所以优化程序的方法诞生出了两个分支：

**大O复杂度：  

一个是宏观上的，也是最有效最直接的，从程序的时间复杂度入手，目的是减少程序的计算量，不管程序指令具体是什么，乘、加、除、判断都认为是一次操作，这样从宏观上评价一个程序的计算量。    

**FLOPS 

另一个是从微观角度出发，当一个程序计算量已经无法再优化了，转而从访存、循环展开、向量化等手段优化时间，尽量让程序更好的利用cpu和存储。使用的是flops指标。

 

## 带宽   
带宽应用的领域非常多，可以用来标识信号传输的数据传输能力、标识单位时间内通过链路的数据量、标识显示器的显示能力。  
**对于存储设备而言，带宽指的是传输能力，指单位时间内能够传输的数据量大小,更直白一点就是数据传输的速度。**    
   
总线带宽指的是总线在单位时间内可以传输的数据总量，等于总线位宽与工作频率的乘积。例如：对于64位、800MHz的前端总线，它的数据传输率就等于     64bit×800×1000×1000Hz÷8(Byte)÷1024÷1024÷1024≈6.0GB/s   
    
内存带宽指的是内存总线所能提供的数据传输能力。例如：DDR400内存的数据传输频率为400MHz，那么单条模组就拥有       64bit×400×1000×1000Hz÷8(Byte)÷1024÷1024÷1024≈3.0GB/s的带宽。   

**n内存带宽 = 数据传输速率 x 数据总线宽度**   
## 常见内存设备的带宽范围：   
   磁盘：  
   内存：   
    RAM:    
      SRAM:   
      DRAM:(动态ram)      
        SDRAM:(synchronous DRAM)同步dram     
          DDR:(double data rate sdram)双倍速率SDRAM   
           DDR4：20GB/S
   SRAM: cache: 1-10ns   
   显存：  
   内存与显存：  
   
   
## 常见芯片的算力    
  
## cycle




## TX2上yolo优化方法  

**看的网上的**
速度优化的方向：

1、减少输入图片的尺寸， 但是相应的准确率可能会有所下降  
2、优化darknet工程源代码（去掉一些不必要的运算量或者优化运算过程）  
3、剪枝和量化yolov3网络（压缩模型---> 减枝可以参考tiny-yolo的过程 ， 量化可能想到的就是定点化可能也需要牺牲精度）  
4、darknet -----> caffe/tensorflow + tensorrt（主要是针对GPU这块的计算优化） 
